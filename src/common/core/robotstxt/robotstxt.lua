local class = require "middleclass"
local plugin = require "bunkerweb.plugin"
local utils = require "bunkerweb.utils"

local ngx = ngx
local ERR = ngx.ERR
local OK = ngx.OK
local get_phase = ngx.get_phase
local subsystem = ngx.config.subsystem
local get_multiple_variables = utils.get_multiple_variables

local template
local render = nil
if subsystem == "http" then
	template = require "resty.template"
	render = template.render
end

local robotstxt = class("robotstxt", plugin)

function robotstxt:initialize(ctx)
	plugin.initialize(self, "robotstxt", ctx)
	if get_phase() ~= "init" then
		local robot_policies, err = self.datastore:get("plugin_robotstxt_policies", true)
		if not robot_policies then
			self.logger:log(ERR, err)
			return
		end
		self.robot_policies = {
			["rule"] = {},
			["sitemap"] = {},
		}
		if robot_policies.global then
			for k, v in pairs(robot_policies.global) do
				self.robot_policies[k] = v
			end
		end
		if robot_policies[self.ctx.bw.server_name] then
			for k, v in pairs(robot_policies[self.ctx.bw.server_name]) do
				self.robot_policies[k] = v
			end
		end
	end
end

function robotstxt:init()
	local variables, err = get_multiple_variables({
		"ROBOTSTXT_RULE",
		"ROBOTSTXT_SITEMAP",
	})
	if variables == nil then
		return self:ret(false, err)
	end
	local data = {}
	local key
	for srv, vars in pairs(variables) do
		if data[srv] == nil then
			data[srv] = {
				["rule"] = {},
				["sitemap"] = {},
			}
		end
		for var, value in pairs(vars) do
			if value ~= "" then
				key = string.lower(string.gsub(string.gsub(var, "^ROBOTSTXT_", ""), "_%d+$", ""))
				data[srv][key][#data[srv][key] + 1] = value
			end
		end
	end
	local ok
	ok, err = self.datastore:set("plugin_robotstxt_policies", data, nil, true)
	if not ok then
		return self:ret(false, err)
	end
	return self:ret(true, "successfully loaded robots.txt policies")
end

function robotstxt:access()
	if self.ctx.bw.uri ~= "/robots.txt" then
		return self:ret(true, "success")
	end
	return self:ret(true, "robots.txt requested", OK)
end

local function sanitize_rules(rules)
	local seen = {}
	local sanitized = {}
	local has_user_agent = false
	for _, rule in ipairs(rules) do
		local trimmed = rule:match("^%s*(.-)%s*$")
		if not seen[trimmed] then
			seen[trimmed] = true
			table.insert(sanitized, trimmed)
			if trimmed:lower():find("^user%-agent:") then
				has_user_agent = true
			end
		end
	end
	if not has_user_agent then
		table.insert(sanitized, 1, "User-agent: *")
	end
	return sanitized
end

local function sanitize_sitemaps(sitemaps)
	local seen = {}
	local sanitized = {}
	for _, url in ipairs(sitemaps) do
		local trimmed = url:match("^%s*(.-)%s*$")
		if trimmed ~= "" then
			-- Force HTTPS for sitemaps
			if trimmed:match("^http://") then
				trimmed = trimmed:gsub("^http://", "https://")
			end
			if not seen[trimmed] then
				seen[trimmed] = true
				table.insert(sanitized, trimmed)
			end
		end
	end
	return sanitized
end

function robotstxt:content()
	if self.variables["USE_ROBOTSTXT"] == "no" then
		return self:ret(true, "robotstxt not activated")
	end
	if self.ctx.bw.uri ~= "/robots.txt" then
		return self:ret(true, "robotstxt not requested")
	end
	-- If no rules are set, use the default rule
	if self.robot_policies["rule"] == nil or #self.robot_policies["rule"] == 0 then
		self.robot_policies["rule"] = { "User-agent: *", "Disallow: /" }
	end
	local data = {}
	for k, v in pairs(self.robot_policies) do
		data[k] = v
	end
	-- Best practices: sanitize rules and sitemaps
	data["rule"] = sanitize_rules(data["rule"])
	data["sitemap"] = sanitize_sitemaps(data["sitemap"])
	-- Add a comment header
	data["header"] = "# robots.txt generated by BunkerWeb (https://bunkerweb.io)"
	render("robots.txt", data)
	return self:ret(true, "content displayed")
end

return robotstxt
